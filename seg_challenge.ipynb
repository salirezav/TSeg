{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import jaccard_score\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import tifffile\n",
    "\n",
    "# PlantSeg imports\n",
    "import plantseg\n",
    "from plantseg.core.zoo import ModelZoo\n",
    "from plantseg.tasks import import_image_task, unet_prediction_task\n",
    "\n",
    "# CellPose imports\n",
    "from cellpose import models, io\n",
    "\n",
    "import napari\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "from plantseg.tasks import import_image_task, unet_prediction_task\n",
    "from plantseg.core import PlantSegImage, ImageProperties, image\n",
    "import cv2\n",
    "from plantseg.core.zoo import ModelZoo\n",
    "\n",
    "mz = ModelZoo(plantseg.PATH_MODEL_ZOO, plantseg.PATH_MODEL_ZOO_CUSTOM)\n",
    "plantseg_model_names = mz.get_model_names()\n",
    "\n",
    "from cellpose import models, utils, io\n",
    "import matplotlib.pyplot as plt\n",
    "import cellpose.models\n",
    "\n",
    "cp_models = [\"cyto3\", \"nuclei\", \"cyto2_cp3\", \"tissuenet_cp3\", \"livecell_cp3\", \"yeast_PhC_cp3\", \"yeast_BF_cp3\", \"bact_phase_cp3\", \"bact_fluor_cp3\", \"deepbacs_cp3\", \"cyto2\", \"cyto\", \"CPx\", \"transformer_cp3\", \"neurips_cellpose_default\", \"neurips_cellpose_transformer\", \"neurips_grayscale_cyto2\", \"CP\", \"CPx\", \"TN1\", \"TN2\", \"TN3\", \"LC1\", \"LC2\", \"LC3\", \"LC4\"]\n",
    "\n",
    "ps_models = [\n",
    "    \"generic_confocal_3D_unet\",\n",
    "    \"generic_light_sheet_3D_unet\",\n",
    "    \"confocal_3D_unet_ovules_ds1x\",\n",
    "    \"confocal_3D_unet_ovules_ds2x\",\n",
    "    \"confocal_3D_unet_ovules_ds3x\",\n",
    "    \"confocal_2D_unet_ovules_ds2x\",\n",
    "    \"lightsheet_3D_unet_root_ds1x\",\n",
    "    \"lightsheet_3D_unet_root_ds2x\",\n",
    "    \"lightsheet_3D_unet_root_ds3x\",\n",
    "    \"lightsheet_2D_unet_root_ds1x\",\n",
    "    \"lightsheet_3D_unet_root_nuclei_ds1x\",\n",
    "    \"lightsheet_2D_unet_root_nuclei_ds1x\",\n",
    "    \"confocal_2D_unet_sa_meristem_cells\",\n",
    "    \"confocal_3D_unet_sa_meristem_cells\",\n",
    "    \"lightsheet_3D_unet_mouse_embryo_cells\",\n",
    "    \"confocal_3D_unet_mouse_embryo_nuclei\",\n",
    "    \"PlantSeg_3Dnuc_platinum\",\n",
    "]\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Suppress PyTorch warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"You are using `torch.load`\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viewer = napari.Viewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to construct the dataset DataFrame\n",
    "def construct_dataset_dataframe(base_dir):\n",
    "    columns = [\"dataset_name\", \"sequence_name\", \"image_path\", \"mask\", \"gold_mask\"] + cp_models + ps_models\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for dataset_name in os.listdir(base_dir):\n",
    "        dataset_path = os.path.join(base_dir, dataset_name)\n",
    "        if not os.path.isdir(dataset_path):\n",
    "            continue\n",
    "\n",
    "        for sequence_name in os.listdir(dataset_path):\n",
    "            sequence_path = os.path.join(dataset_path, sequence_name)\n",
    "            if not os.path.isdir(sequence_path) or \"_\" in sequence_name:\n",
    "                continue\n",
    "\n",
    "            # Paths for masks and gold masks\n",
    "            err_seg_path = os.path.join(dataset_path, f\"{sequence_name}_ERR_SEG\")\n",
    "            gt_seg_path = os.path.join(dataset_path, f\"{sequence_name}_GT\", \"SEG\")\n",
    "\n",
    "            for image_file in os.listdir(sequence_path):\n",
    "                if image_file.endswith(\".tif\"):\n",
    "                    image_path = os.path.join(sequence_path, image_file)\n",
    "\n",
    "                    # Corresponding mask and gold mask paths\n",
    "                    mask_path = os.path.join(err_seg_path, f\"mask{image_file[1:]}\")\n",
    "                    mask_path = mask_path if os.path.exists(mask_path) else None\n",
    "\n",
    "                    gold_mask_path = os.path.join(gt_seg_path, f\"man_seg{image_file[1:]}\")\n",
    "                    gold_mask_path = gold_mask_path if os.path.exists(gold_mask_path) else None\n",
    "\n",
    "                    # Append a row with default None values for models\n",
    "                    data.append([dataset_name, sequence_name, image_path, mask_path, gold_mask_path] + [None] * (len(columns) - 5))\n",
    "\n",
    "    return pd.DataFrame(data, columns=columns)\n",
    "\n",
    "\n",
    "# Define the base directory (update this to your actual dataset path)\n",
    "base_dir = \"./datasets\"\n",
    "\n",
    "# Create the DataFrame\n",
    "dataset_df = construct_dataset_dataframe(base_dir)\n",
    "\n",
    "# Save or display the DataFrame\n",
    "print(dataset_df.head())\n",
    "# Optionally save to a CSV file\n",
    "dataset_df.to_csv(\"dataset_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for loading images\n",
    "def load_image(file_path):\n",
    "    return cv2.imread(file_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "\n",
    "# # Function to perform segmentation using PlantSeg\n",
    "# def segment_with_plantseg(image_path, model_name=\"lightsheet_2D_unet_root_ds1x\", patch=(1, 64, 64), device=\"cuda\"):\n",
    "#     plantseg_image = import_image_task(input_path=Path(image_path), semantic_type=\"raw\", stack_layout=\"YX\")\n",
    "#     predicted_images = unet_prediction_task(image=plantseg_image, model_name=model_name, patch=patch, device=device)\n",
    "#     # Return the first predicted image\n",
    "#     return predicted_images[0].get_data()\n",
    "\n",
    "\n",
    "# # Function to perform segmentation using CellPose\n",
    "# def segment_with_cellpose(image_path, model_type=\"cyto2\", flow_threshold=0.4, cellprob_threshold=0):\n",
    "#     image = io.imread(image_path)\n",
    "#     model = models.Cellpose(gpu=True, model_type=model_type)\n",
    "#     masks, flows, styles, diams = model.eval(image, diameter=None, channels=[0, 0], flow_threshold=flow_threshold, cellprob_threshold=cellprob_threshold)\n",
    "#     return masks\n",
    "\n",
    "\n",
    "# Function for calculating IoU with ground truth\n",
    "def calculate_iou(pred, gt):\n",
    "    pred_flat = pred.flatten()\n",
    "    gt_flat = gt.flatten()\n",
    "    return jaccard_score(gt_flat, pred_flat, average=\"binary\")\n",
    "\n",
    "\n",
    "def get_images_for_masks(gt_gold_paths, image_paths):\n",
    "    subset_paths = []\n",
    "    for p in gt_gold_paths:\n",
    "        first_gt_gold_file = os.path.basename(p)\n",
    "        # Extract digits from the filename\n",
    "        digits = int(re.findall(r\"\\d+\", first_gt_gold_file)[0])\n",
    "        subset_paths.append(image_paths[digits])\n",
    "    return subset_paths\n",
    "\n",
    "\n",
    "# def segment(image_path, model_name):\n",
    "#     if model_name in cp_models:\n",
    "#         return segment_with_cellpose(image_path, model_type=model_name)\n",
    "#     elif model_name in ps_models:\n",
    "#         return segment_with_plantseg(image_path, model_name=model_name)\n",
    "#     else:\n",
    "#         raise ValueError(f\"Unknown model name: {model_name}\")\n",
    "\n",
    "\n",
    "# def seg_with_CellPose(image_path, model_type=\"cyto2\", diameter=None):\n",
    "#     image = io.imread(image_path)\n",
    "#     model = models.CellposeModel(gpu=True, model_type=model_type)\n",
    "#     masks, flows, styles = model.eval(image, diameter=diameter, channels=[0, 0], flow_threshold=0.4, cellprob_threshold=0)\n",
    "#     return masks\n",
    "\n",
    "\n",
    "# def seg_with_PlantSeg(image_path, model_name=\"lightsheet_2D_unet_root_ds1x\", patch=(1, 64, 64), device=\"cuda\"):\n",
    "#     plantseg_image = import_image_task(input_path=Path(image_path), semantic_type=\"raw\", stack_layout=\"YX\")\n",
    "#     predicted_images = unet_prediction_task(image=plantseg_image, model_name=model_name, patch=patch, device=device)\n",
    "#     return predicted_images[0].get_data()\n",
    "\n",
    "\n",
    "def ins_to_sem(mask):\n",
    "    # Convert instance segmentation mask to semantic mask\n",
    "    mask = mask.astype(np.uint8)\n",
    "    mask = mask * 255\n",
    "    mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
    "    mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "    return mask\n",
    "\n",
    "\n",
    "# def calc_jaccard_score(pred, gt):\n",
    "#     pred_flat = pred.flatten()\n",
    "#     gt_flat = gt.flatten()\n",
    "#     return jaccard_score(gt_flat, pred_flat, average=\"micro\")\n",
    "\n",
    "\n",
    "# def calc_jaccard_score_per_object(pred, gt):\n",
    "#     # Unique labels for reference objects (ground truth) and predicted objects\n",
    "#     gt_labels = np.unique(gt)\n",
    "#     pred_labels = np.unique(pred)\n",
    "\n",
    "#     # Remove background label (assumed to be 0)\n",
    "#     gt_labels = gt_labels[gt_labels > 0]\n",
    "#     pred_labels = pred_labels[pred_labels > 0]\n",
    "\n",
    "#     jaccard_scores = []\n",
    "\n",
    "#     for gt_label in gt_labels:\n",
    "#         # Extract pixels for the current reference object\n",
    "#         gt_object = gt == gt_label\n",
    "\n",
    "#         # Find the matching predicted object with maximum overlap\n",
    "#         best_iou = 0\n",
    "#         for pred_label in pred_labels:\n",
    "#             pred_object = pred == pred_label\n",
    "#             intersection = np.logical_and(gt_object, pred_object).sum()\n",
    "#             union = np.logical_or(gt_object, pred_object).sum()\n",
    "\n",
    "#             if union > 0:\n",
    "#                 iou = intersection / union\n",
    "#                 best_iou = max(best_iou, iou)\n",
    "\n",
    "#         # Append the best IoU for this ground truth object\n",
    "#         jaccard_scores.append(best_iou)\n",
    "\n",
    "#     # Mean IoU across all ground truth objects\n",
    "#     return np.mean(jaccard_scores) if jaccard_scores else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, row in dataset_df.iterrows():\n",
    "\n",
    "#     for model in cp_models + ps_models:\n",
    "#         image_path = row[\"image_path\"][0]  # Assuming you want to use the first image in the list\n",
    "#         gt_path = row[\"gt_path\"][0]  # Assuming you want to use the first ground truth in the list\n",
    "#         gt_gold_path = row[\"gt_gold_path\"][0]  # Assuming you want to use the first ground truth gold in the list\n",
    "\n",
    "#         # Perform segmentation\n",
    "#         segmented_image = segment(image_path, model_name=model)\n",
    "\n",
    "#         # Convert instance segmentation to semantic segmentation\n",
    "#         semantic_mask = ins_to_sem(segmented_image)\n",
    "\n",
    "#         # Load ground truth\n",
    "#         gt_image = load_image(gt_gold_path)\n",
    "#         gt_semantic = ins_to_sem(gt_image)\n",
    "\n",
    "#         # Calculate IoU score\n",
    "#         iou_score = calc_jaccard_score_per_object(semantic_mask, gt_semantic)\n",
    "#         print(f\"Model: {model}, IoU Score: {iou_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform segmentation\n",
    "def segment(image_path, model_name, dimension=\"2D\"):\n",
    "    twoD_ps_models = [model for model in ps_models if \"2D\" in model]\n",
    "    threeD_ps_models = [ps for ps in ps_models if \"3D\" in ps]\n",
    "    if model_name in cp_models:\n",
    "        model = models.CellposeModel(gpu=True, model_type=model_name)\n",
    "        image = io.imread(image_path)\n",
    "        masks, _, _ = model.eval(image, diameter=None, channels=[0, 0], flow_threshold=0.4, cellprob_threshold=0)\n",
    "        return masks\n",
    "    elif model_name in twoD_ps_models:\n",
    "        plantseg_image = import_image_task(input_path=Path(image_path), semantic_type=\"raw\", stack_layout=\"YX\")\n",
    "        predicted_images = unet_prediction_task(image=plantseg_image, model_name=model_name, model_id=None, patch=(1, 64, 64), device=\"cuda\")\n",
    "        return predicted_images[0].get_data()\n",
    "    elif model_name in threeD_ps_models:\n",
    "        plantseg_image = import_image_task(input_path=Path(image_path), semantic_type=\"raw\", stack_layout=\"ZYX\")\n",
    "        predicted_images = unet_prediction_task(image=plantseg_image, model_name=model_name, model_id=None, patch=(4, 64, 64), device=\"cuda\")\n",
    "        return predicted_images[0].get_data()\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model name: {model_name}\")\n",
    "\n",
    "\n",
    "# # Function to calculate Jaccard score\n",
    "# def calculate_jaccard_score(predicted_mask, ground_truth_mask):\n",
    "#     # Ensure both masks are the same data type\n",
    "#     pred_flat = predicted_mask.flatten().astype(np.int32)\n",
    "#     gt_flat = ground_truth_mask.flatten().astype(np.int32)\n",
    "#     return jaccard_score(gt_flat, pred_flat, average=\"micro\")\n",
    "\n",
    "\n",
    "def calculate_jaccard_score(predicted_mask, ground_truth_mask):\n",
    "    \"\"\"\n",
    "    Calculate the Jaccard Index (IoU) for 2D or 3D masks.\n",
    "\n",
    "    Parameters:\n",
    "    - predicted_mask: np.array, predicted mask of shape (X, Y) or (Z, X, Y).\n",
    "    - ground_truth_mask: np.array, ground truth mask of shape (X, Y) or (Z, X, Y).\n",
    "\n",
    "    Returns:\n",
    "    - jaccard_score: float, IoU for 2D data or averaged IoU for 3D data.\n",
    "    \"\"\"\n",
    "    # Ensure both masks have the same shape\n",
    "    assert predicted_mask.shape == ground_truth_mask.shape, f\"Masks must have the same shape. but they're pred:{predicted_mask.shape} and gt:{ground_truth_mask.shape}\"\n",
    "\n",
    "    # Flatten and calculate IoU for 2D data\n",
    "    if predicted_mask.ndim == 2:\n",
    "        pred_flat = predicted_mask.flatten().astype(np.int32)\n",
    "        gt_flat = ground_truth_mask.flatten().astype(np.int32)\n",
    "        return jaccard_score(gt_flat, pred_flat, average=\"micro\")\n",
    "\n",
    "    # Process 3D data (compute IoU for each slice, then average)\n",
    "    elif predicted_mask.ndim == 3:\n",
    "        jaccard_scores = []\n",
    "        for z in range(predicted_mask.shape[0]):  # Iterate through slices\n",
    "            pred_flat = predicted_mask[z].flatten().astype(np.int32)\n",
    "            gt_flat = ground_truth_mask[z].flatten().astype(np.int32)\n",
    "            jaccard_scores.append(jaccard_score(gt_flat, pred_flat, average=\"micro\"))\n",
    "        return np.mean(jaccard_scores)  # Average over all slices\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Input masks must be 2D or 3D arrays.\")\n",
    "\n",
    "\n",
    "# Main processing loop\n",
    "def process_dataset(df, models):\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing dataset\", position=0):\n",
    "        try:\n",
    "            image_path = row[\"image_path\"]\n",
    "            mask_path = row[\"mask\"] if pd.notna(row[\"mask\"]) else row[\"gold_mask\"]\n",
    "\n",
    "            assert image_path is not None\n",
    "            assert mask_path is not None\n",
    "\n",
    "            if not mask_path or not os.path.exists(mask_path):\n",
    "                continue\n",
    "\n",
    "            ground_truth_mask = tifffile.imread(mask_path)\n",
    "\n",
    "            for model_name in models:\n",
    "                if pd.notna(row.get(model_name)):\n",
    "                    print(f\"skipping {row['dataset_name']}\")\n",
    "                    continue  # Skip if Jaccard is already calculated\n",
    "                try:\n",
    "                    print(f\"Processing dataset {row['dataset_name']} with model {model_name}\")\n",
    "                    predicted_mask = segment(image_path, model_name)\n",
    "                    iou_score = calculate_jaccard_score(predicted_mask, ground_truth_mask)\n",
    "                    df.at[idx, model_name] = iou_score\n",
    "                    print(\"JACCARD SCORE IS:\", iou_score)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing model {model_name} for image {image_path}: {e}\")\n",
    "        except Exception as e:\n",
    "            # print(f\"Error processing row {idx} for model {model_name}: {e}\")\n",
    "            print(image_path)\n",
    "            print(mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_df = pd.read_csv(\"dataset_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = pd.read_csv(\"sample_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_df = dataset_df.dropna(subset=[\"mask\", \"gold_mask\"], how=\"all\")\n",
    "# sampled_df = filter_df.groupby([\"dataset_name\", \"sequence_name\"], group_keys=False).apply(lambda x: x.sample(n=min(5, len(x)), random_state=42)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_models = [f for f in ps_models if \"2D\" in f]\n",
    "the_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process_dataset(sampled_df, the_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampled_df.to_csv(\"sample3D_summary.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_df.to_csv(\"dataset_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = sampled_df[\"image_path\"][0]\n",
    "image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plantseg_image = import_image_task(input_path=Path(image_path), semantic_type=\"raw\", stack_layout=\"ZYX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_images = unet_prediction_task(image=plantseg_image, model_name=the_models[0], model_id=None, patch=(1, 64, 64), device=\"cuda\")\n",
    "# Return the first predicted image\n",
    "plt.imshow(predicted_images[0].get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns representing the models\n",
    "model_columns = cp_models + ps_models\n",
    "\n",
    "# Group by dataset and sequence, then calculate the mean IoU for each model\n",
    "average_iou = sampled_df.groupby([\"dataset_name\", \"sequence_name\"])[model_columns].mean().reset_index()\n",
    "\n",
    "# Calculate overall average IoU across datasets\n",
    "overall_average_iou = average_iou[model_columns].mean().to_dict()\n",
    "\n",
    "average_iou, overall_average_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_average_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_df = dataset_df.dropna(subset=[\"mask\", \"gold_mask\"], how=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_3d_df = filter_df[filter_df[\"dataset_name\"].str.contains(\"3D\")]\n",
    "filtered_3d_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_3D_df = filtered_3d_df.groupby([\"dataset_name\", \"sequence_name\"], group_keys=False).apply(lambda x: x.sample(n=min(1, len(x)), random_state=42)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_3D_df = pd.read_csv(\"sample3D_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the values under dataset_name in sampled_3D_df and sampled_df are the same\n",
    "same_values = sampled_3D_df[\"dataset_name\"].equals(sampled_df[\"dataset_name\"])\n",
    "print(same_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_3D_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = sampled_3D_df[\"image_path\"][0]\n",
    "image_path\n",
    "plantseg_image = import_image_task(input_path=Path(image_path), semantic_type=\"raw\", stack_layout=\"ZYX\")\n",
    "predicted_images = unet_prediction_task(image=plantseg_image, model_name=ps_models[0], model_id=None, patch=(4, 64, 64), device=\"cuda\")\n",
    "# Return the first predicted image\n",
    "# plt.imshow(predicted_images[0].get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mask = predicted_images[0].get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_image(predicted_images[0].get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_path = sampled_3D_df[\"mask\"][0]\n",
    "import tifffile\n",
    "\n",
    "mask = tifffile.imread(mask_path)\n",
    "# viewer.add_image(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "\n",
    "# def calculate_jaccard_index(predicted_mask, ground_truth_mask):\n",
    "#     \"\"\"\n",
    "#     Calculate the Jaccard Index (IoU) for 3D masks.\n",
    "\n",
    "#     Parameters:\n",
    "#     - predicted_mask: np.array, predicted mask of shape (Z, X, Y). Can be binary or multi-class.\n",
    "#     - ground_truth_mask: np.array, ground truth mask of shape (Z, X, Y). Can be binary or multi-class.\n",
    "\n",
    "#     Returns:\n",
    "#     - jaccard_index: float or dict, IoU score(s) for binary or per class if multi-class.\n",
    "#     \"\"\"\n",
    "#     # Ensure masks are the same shape\n",
    "#     assert predicted_mask.shape == ground_truth_mask.shape, \"Masks must have the same shape.\"\n",
    "\n",
    "#     # Convert masks to a consistent binary format (np.bool_)\n",
    "#     predicted_mask = np.asarray(predicted_mask, dtype=bool)\n",
    "#     ground_truth_mask = np.asarray(ground_truth_mask, dtype=bool)\n",
    "\n",
    "#     if np.array_equal(np.unique(predicted_mask), [False, True]) and np.array_equal(np.unique(ground_truth_mask), [False, True]):\n",
    "#         # Binary case\n",
    "#         intersection = np.logical_and(predicted_mask, ground_truth_mask)\n",
    "#         union = np.logical_or(predicted_mask, ground_truth_mask)\n",
    "#         return np.sum(intersection) / np.sum(union) if np.sum(union) > 0 else 1.0  # Handle zero union case\n",
    "\n",
    "#     else:\n",
    "#         # Multi-class case\n",
    "#         classes = np.unique(ground_truth_mask)\n",
    "#         iou_scores = {}\n",
    "#         for cls in classes:\n",
    "#             pred_binary = predicted_mask == cls\n",
    "#             gt_binary = ground_truth_mask == cls\n",
    "#             intersection = np.logical_and(pred_binary, gt_binary)\n",
    "#             union = np.logical_or(pred_binary, gt_binary)\n",
    "#             iou_scores[cls] = np.sum(intersection) / np.sum(union) if np.sum(union) > 0 else 1.0\n",
    "#         return iou_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "\n",
    "jaccard_index = calculate_jaccard_score(pred_mask, mask)\n",
    "print(\"Jaccard Index:\", jaccard_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_3D_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_3d_models = [ps for ps in ps_models if \"3D\" in ps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 1101/1650 [03:01<01:30,  6.06it/s]\n",
      "Processing dataset:  20%|██        | 2/10 [33:19<2:13:17, 999.71s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m reversed_sampled_3D_df \u001b[38;5;241m=\u001b[39m sampled_3D_df\u001b[38;5;241m.\u001b[39miloc[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m2\u001b[39m:]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Pass the reversed dataframe to the function\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mprocess_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreversed_sampled_3D_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mps_3d_models\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 84\u001b[0m, in \u001b[0;36mprocess_dataset\u001b[0;34m(df, models)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing dataset \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 84\u001b[0m     predicted_mask \u001b[38;5;241m=\u001b[39m \u001b[43msegment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     iou_score \u001b[38;5;241m=\u001b[39m calculate_jaccard_score(predicted_mask, ground_truth_mask)\n\u001b[1;32m     86\u001b[0m     df\u001b[38;5;241m.\u001b[39mat[idx, model_name] \u001b[38;5;241m=\u001b[39m iou_score\n",
      "Cell \u001b[0;32mIn[17], line 16\u001b[0m, in \u001b[0;36msegment\u001b[0;34m(image_path, model_name, dimension)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m threeD_ps_models:\n\u001b[1;32m     15\u001b[0m     plantseg_image \u001b[38;5;241m=\u001b[39m import_image_task(input_path\u001b[38;5;241m=\u001b[39mPath(image_path), semantic_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m, stack_layout\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZYX\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m     predicted_images \u001b[38;5;241m=\u001b[39m \u001b[43munet_prediction_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplantseg_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predicted_images[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_data()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/space/alireza/tseg/.conda/lib/python3.11/site-packages/plantseg/tasks/workflow_handler.py:336\u001b[0m, in \u001b[0;36mtask_tracker.<locals>._inner_decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    333\u001b[0m         parameters[name] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m    335\u001b[0m \u001b[38;5;66;03m# Execute the function\u001b[39;00m\n\u001b[0;32m--> 336\u001b[0m out_image \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;66;03m# Parse the output\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out_image \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/space/alireza/tseg/.conda/lib/python3.11/site-packages/plantseg/tasks/prediction_tasks.py:40\u001b[0m, in \u001b[0;36munet_prediction_task\u001b[0;34m(image, model_name, model_id, suffix, patch, patch_halo, single_batch_mode, device, model_update, disable_tqdm, config_path, model_weights_path)\u001b[0m\n\u001b[1;32m     37\u001b[0m data \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mget_data()\n\u001b[1;32m     38\u001b[0m input_layout \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mimage_layout\n\u001b[0;32m---> 40\u001b[0m pmaps \u001b[38;5;241m=\u001b[39m \u001b[43munet_prediction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_layout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_layout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatch_halo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatch_halo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43msingle_batch_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msingle_batch_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_update\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_update\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable_tqdm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_tqdm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_weights_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_weights_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m pmaps\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 4D CZXY prediction, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpmaps\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     56\u001b[0m new_images \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/space/alireza/tseg/.conda/lib/python3.11/site-packages/plantseg/functionals/prediction/prediction.py:233\u001b[0m, in \u001b[0;36munet_prediction\u001b[0;34m(raw, input_layout, model_name, model_id, patch, patch_halo, single_batch_mode, device, model_update, disable_tqdm, config_path, model_weights_path)\u001b[0m\n\u001b[1;32m    228\u001b[0m slice_builder \u001b[38;5;241m=\u001b[39m SliceBuilder(raw, label_dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, patch_shape\u001b[38;5;241m=\u001b[39mpatch, stride_shape\u001b[38;5;241m=\u001b[39mstride)\n\u001b[1;32m    229\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m ArrayDataset(\n\u001b[1;32m    230\u001b[0m     raw, slice_builder, augs, halo_shape\u001b[38;5;241m=\u001b[39mpatch_halo, multichannel\u001b[38;5;241m=\u001b[39mmultichannel_input, verbose_logging\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    231\u001b[0m )\n\u001b[0;32m--> 233\u001b[0m pmaps \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pmaps either (C, Z, Y, X) or (C, Y, X)\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pmaps\n",
      "File \u001b[0;32m/space/alireza/tseg/.conda/lib/python3.11/site-packages/plantseg/functionals/prediction/utils/array_predictor.py:172\u001b[0m, in \u001b[0;36mArrayPredictor.__call__\u001b[0;34m(self, test_dataset)\u001b[0m\n\u001b[1;32m    170\u001b[0m prediction \u001b[38;5;241m=\u001b[39m remove_padding(prediction, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_halo)\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# convert to numpy array\u001b[39;00m\n\u001b[0;32m--> 172\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mprediction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    174\u001b[0m channel_slice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;241m0\u001b[39m, out_channels)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;66;03m# for each batch sample\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Reverse the dataframe and skip the last two rows\n",
    "reversed_sampled_3D_df = sampled_3D_df.iloc[::-1].iloc[2:]\n",
    "rever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pass the reversed dataframe to the function\n",
    "process_dataset(reversed_sampled_3D_df, ps_3d_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_dataset(sampled_3D_df, ps_3d_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_3D_df.to_csv(\"sample3D_summary.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"deepbacs_cp3\"\n",
    "image_path = sampled_3D_df[\"image_path\"][11]\n",
    "gt_mask = sampled_3D_df[\"mask\"][11]\n",
    "image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = segment(image_path, \"cyto3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = tifffile.imread(image_path)\n",
    "gt_mask = tifffile.imread(gt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 34\n",
    "plt.imshow(gt_mask[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "jac = calculate_jaccard_score(mask[i], gt_mask[i])\n",
    "jac"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
